<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>内存管理——概念</title>
      <link href="/2021/07/24/%E5%86%85%E5%AD%98%E7%AE%A1%E7%90%86%E2%80%94%E2%80%94%E6%A6%82%E5%BF%B5/"/>
      <url>/2021/07/24/%E5%86%85%E5%AD%98%E7%AE%A1%E7%90%86%E2%80%94%E2%80%94%E6%A6%82%E5%BF%B5/</url>
      
        <content type="html"><![CDATA[<p>在早期的计算机中，程序是直接运行在物理内存上的。即程序在运行的过程中访问的都是物理地址。如果这个系统只运行一个程序，那么只要这个程序所需的内存不要超过该机器的物理内存就不会出现问题。</p><p>然而现在的系统都是支持多任务，多进程的，这样CPU以及其他硬件的利用率会更高，这个时候就要考虑到将系统内有限的物理内存如何及时有效的分配给多个程序了，这个事情本身就称之为****内存管理****。</p><p>1）下面举一个早期的计算机系统中内存分配管理的例子：</p><p>假如有三个程序，程序A，B，C，程序A运行的过程中需要10M内存，程序B运行的过程中需要100M内存，而程序C运行的过程中需要20M内存。如果系统同时需要运行程序A和B，那么早期的内存管理过程大概是这样的。</p><p>将物理内存的前10M分配给A，接下来的10M-110M分配给B。这种内存管理的方法比较直接，假设这个时候想让程序C也运行，同时假设系统的内存只有128M，显然按照这种方法程序C由于内存不够是不能够运行的。</p><p>这个时候就需要虚拟内存技术 了，内存空间不够的时候可以将程序不需要用到的数据交换到磁盘空间上去，已达到扩展内存空间的目的。</p><p>2）内存管理中存在的问题</p><p>（1）进程地址空间不能隔离</p><p>由于程序直接访问的是物理内存，这个时候程序所使用的内存空间不是隔离的。举个例子，就像上面说的A的地址空间是0-10M这个范围内，但是如果A中有一段代码是操作10M-128M这段地址空间内的数据，那么程序B和程序C就很可能会崩溃（每个程序都可以访问系统的整个地址空间）。这样很多恶意程序或者是木马程序可以轻而易举地破快其他的程序，系统的安全性也就得不到保障了，这对用户来说也是不能容忍的。</p><p>（2）内存使用的效率低</p><p>如果要让程序A、B、C同时运行，那么唯一的方法就是使用虚拟内存技术将一些程序暂时不用的数据写到磁盘上，在需要的时候再从磁盘读回内存。</p><p>这里程序C要运行，将A交换到磁盘上去显然是不行的，因为程序是需要连续的地址空间的，程序C需要20M的内存，而A只有10M的空间，所以需要将程序B交换到磁盘上去，而B足足有100M，可以看到为了运行程序C我们需要将100M的数据从内存写到磁盘，然后在程序B需要运行的时候再从磁盘读到内存，而IO操作比较耗时，所以这个过程效率将会十分低下。</p><p>（3）程序运行的地址不能确定</p><p>程序每次需要运行时，都需要在内存中分配一块足够大的空闲区域，而问题是这个空闲的位置是不能确定的，这会带来一些重定位的问题，重定位的问题确定就是程序中引用的变量和函数的地址。</p><p>内存管理为了解决上面三个问题，引入了一个中间层，即程序和物理内存之间的****虚拟内存****。</p><p>程序只能看见虚拟内存，再也不能直接访问物理内存。每个程序都有自己独立的进程地址空间，这样就做到了进程隔离。这里的进程地址空间是指虚拟地址。顾名思义，既然是虚拟地址，也就是虚的，不是现实存在的地址空间。</p><p>既然程序和物理地址空间之间增加了虚拟地址，那么就要解决怎么从虚拟地址映射到物理地址，因为程序最终肯定是运行在物理内存中的，主要有分段和分页两种技术。</p>]]></content>
      
      
      <categories>
          
          <category> 内存管理 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> linux </tag>
            
            <tag> mem </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>内存管理——内存映射</title>
      <link href="/2021/07/24/%E5%86%85%E5%AD%98%E7%AE%A1%E7%90%86%E2%80%94%E2%80%94%E5%86%85%E5%AD%98%E6%98%A0%E5%B0%84/"/>
      <url>/2021/07/24/%E5%86%85%E5%AD%98%E7%AE%A1%E7%90%86%E2%80%94%E2%80%94%E5%86%85%E5%AD%98%E6%98%A0%E5%B0%84/</url>
      
        <content type="html"><![CDATA[<h2 id="1-分段机制"><a href="#1-分段机制" class="headerlink" title="1. 分段机制"></a>1. <strong>分段机制</strong></h2><p><img src="%E5%88%86%E6%AE%B5%E6%9C%BA%E5%88%B6.png" alt="分段机制"></p><p>&emsp;&emsp;<strong>分段</strong>(Segmentation)：是人们最开始使用的一种方法，基本思路是将程序所需要的内存地址空间大小的虚拟空间映射到某个物理地址空间。</p><p>&emsp;&emsp;每个程序都有其独立的虚拟的独立的进程地址空间，可以看到程序A和B的虚拟地址空间都是从0x00000000开始的。将两块大小相同的虚拟地址空间和实际物理地址空间一一映射，即虚拟地址空间中的每个字节对应于实际地址空间中的每个字节，这个映射过程由软件来设置映射的机制，实际的转换由硬件来完成。</p><p>&emsp;&emsp;这种分段的机制解决了之前提到的3个问题中的进程地址空间隔离和程序地址重定位的问题。</p><p>&emsp;&emsp;程序A和程序B有自己独立的虚拟地址空间，而且该虚拟地址空间被映射到了互相不重叠的物理地址空间，如果程序A访问虚拟地址空间的地址不在0x00000000-0x00A00000这个范围内，那么内核就会拒绝这个请求，所以它解决了隔离地址空间的问题。</p><p>&emsp;&emsp;应用程序A只需要关心其虚拟地址空间0x00000000-0x00A00000，而其被映射到哪个物理地址无需关心，所以程序永远按照这个虚拟地址空间来放置变量，代码，不需要重新定位。</p><p>&emsp;&emsp;虽然分段机制解决了上面两个问题，但是对于内存效率问题仍然无能为力。因为这种内存映射机制仍然是以程序为单位，当内存不足时仍然需要将整个程序交换到磁盘，这样内存使用的效率仍然很低。</p><p>&emsp;&emsp;那么，怎么才算高效率的内存使用呢。事实上，根据程序的局部性运行原理，一个程序在运行的过程当中，在某个时间段内，只有一小部分数据会被经常用到。所以需要更加小粒度的内存分割和映射方法，所以，另一种将虚拟地址转换为物理地址的方法——分页机制应运而生了。</p><p>&emsp;&emsp;由于分段和分页都是划分进程物理地址空间，区别在于分段是给每个进程分配不同的线性地址空间，而分页是把线性地址空间映射到不同的物理地址空间，所以，分页机制就已经足够实现内存管理的功能。</p><p>&emsp;&emsp;而且，分段机制的起源是intel 8086的CPU体系结构ALU运算宽度与地址总线宽度不一致（16位和20位），而后续的intel处理器又为了向上兼容的遗留产物 。</p><center>表1-1 intel处理器</center><table><thead><tr><th>型号</th><th>位宽</th><th>总线位宽</th><th>地址位宽</th><th>寻址范围</th><th>备注</th></tr></thead><tbody><tr><td>4004</td><td>4</td><td>4</td><td>—</td><td>640B</td><td>1971/11/15</td></tr><tr><td>8008</td><td>8</td><td>8</td><td>—</td><td>16KB</td><td>1972/04/01</td></tr><tr><td>8080</td><td>8</td><td>8</td><td>16</td><td>64KB</td><td>1974/04/01</td></tr><tr><td>8086</td><td>16</td><td>16</td><td>20</td><td>1MB</td><td>1978/06/08</td></tr><tr><td>8088</td><td>16</td><td>8</td><td>20</td><td>1MB</td><td>1979/06/01</td></tr><tr><td>80186</td><td>16</td><td>16</td><td>20</td><td>1MB</td><td>1982年，比8086多了几条指令</td></tr><tr><td>80286</td><td>16</td><td>16</td><td>24</td><td>16MB</td><td>1982年，内存保护模式，多用户多任务</td></tr><tr><td>80386</td><td>32</td><td>32</td><td>32</td><td>4GB</td><td>1985年，支持虚拟内存</td></tr><tr><td>80486</td><td>32</td><td>32</td><td>32</td><td>4GB</td><td>1989年，集成数字协处理器80387和8KB高速缓存，采用RISC技术</td></tr></tbody></table><p>&emsp;&emsp;因此，几乎所有RISC体系结构的处理器都不支持分段机制，而只采用了分页机制。所以，linux为了移植性和简化内存管理（共享一组线性地址），只在80x86结构下才使用分段机制。这就是为什么linux没有线性地址，而只有虚拟地址和物理地址的原因。</p><h2 id="2-分页机制"><a href="#2-分页机制" class="headerlink" title="2. 分页机制"></a>2. <strong>分页机制</strong></h2><p>&emsp;&emsp;<strong>分页</strong>机制：把内存地址空间分为若干个很小的固定大小的页，每一页的大小由内存决定，就像Linux中ext文件系统将磁盘分成若干个Block一样，这样做是分别是为了提高内存和磁盘的利用率。</p><p>&emsp;&emsp;试想一下，如果将磁盘空间分成N等份，每一份的大小(一个Block)是1M，如果想存储在磁盘上的文件是1K字节，那么其余的999字节便浪费了。所以需要更加细粒度的磁盘分割方式，可以将Block设置得小一点。</p><p>&emsp;&emsp;linux一般页的大小是4KB，并把进程的地址空间按页分割，把常用的数据和代码页装载到内存中，不常用的代码和数据保存在磁盘中，以一个例子来说明，如下图：</p><p><img src="%E5%88%86%E9%A1%B5%E6%9C%BA%E5%88%B6.png" alt="分页机制"></p><p>&emsp;&emsp;可以看到进程1和进程2的虚拟地址空间都被映射到了不连续的物理地址空间内(这个意义很大，如果有一天我们的连续物理地址空间不够，但是不连续的地址空间很多，如果没有这种技术，我们的程序就没有办法运行),甚至他们共用了一部分物理地址空间，这就是共享内存。</p><p>&emsp;&emsp;进程1的虚拟页VP2和VP3被交换到了磁盘中，在程序需要这两页的时候，Linux内核会产生一个缺页异常，然后异常管理程序会将其读到内存中。</p><p>&emsp;&emsp;这就是分页机制的原理，不过Linux中的分页机制的实现还是比较复杂的，使用的是一种与具体体系结构无关代码的四级页表机制——通过页全局目录，页上级目录，页中间目录，页表的分页机制来实现的。</p><p><img src="linux%E7%9A%84%E5%88%86%E9%A1%B5%E6%9C%BA%E5%88%B6.png" alt="linux的分页机制"></p><p>&emsp;&emsp;分页机制的实现需要硬件的实现，这个硬件名字叫做<strong>MMU</strong>(Memory Management Unit)，他就是专门负责从虚拟地址到物理地址转换的，也就是从虚拟页找到物理页。</p>]]></content>
      
      
      <categories>
          
          <category> 内存管理 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> linux </tag>
            
            <tag> mem </tag>
            
        </tags>
      
    </entry>
    
    
  
  
</search>
